{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla input: \t torch.Size([1, 3, 32, 32])\n",
      "3D input: \t torch.Size([1, 1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ceconv2d import CEConv2D\n",
    "\n",
    "# Generate dummy input.\n",
    "x = torch.rand(1, 3, 32, 32)\n",
    "x_hidden = torch.rand(1, 16, 3, 32, 32)\n",
    "\n",
    "# Add extra \"temporal\" dimension to input.\n",
    "x_3d = x.unsqueeze(1)\n",
    "\n",
    "print(\"Vanilla input: \\t\", x.shape)\n",
    "print(\"3D input: \\t\", x_3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifting layer\n",
    "\n",
    "Lifting layer of Color Equivariant Convolution (CEConv) is equivalent to a 3D convolution over the color channels with circular padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: \t torch.Size([16, 3, 1, 3, 3])\n",
      "Output tensor: \t torch.Size([1, 16, 3, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "# Define \"vanilla\" color equivariant model with single lifting layer.\n",
    "model_vanilla = nn.Sequential(\n",
    "    CEConv2D(\n",
    "        in_rotations=1,\n",
    "        out_rotations=3,\n",
    "        in_channels=3,\n",
    "        out_channels=16,\n",
    "        kernel_size=3,\n",
    "        padding=0,\n",
    "    ),\n",
    ")\n",
    "print(\"Weight: \\t\", model_vanilla[0].weight.shape)\n",
    "\n",
    "# Forward pass.\n",
    "y_vanilla = model_vanilla(x)\n",
    "print(\"Output tensor: \\t\", y_vanilla.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: \t torch.Size([16, 1, 3, 3, 3])\n",
      "Output tensor \t torch.Size([1, 16, 3, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "# Define Conv3d implementation of color equivariant model.\n",
    "model_3d = nn.Sequential(\n",
    "    nn.Conv3d(\n",
    "        in_channels=1,\n",
    "        out_channels=16,\n",
    "        kernel_size=(3, 3, 3),  # temporal dimension is 3 because RGB\n",
    "        padding=(1, 0, 0),  # we apply padding to the temporal dimension\n",
    "        padding_mode='circular',  # and we use circular padding\n",
    "    ),\n",
    ")\n",
    "print(\"Weight: \\t\", model_3d[0].weight.shape)\n",
    "\n",
    "# Copy weights from vanilla model to 3D model.\n",
    "w = model_vanilla[0].weight.data\n",
    "w = torch.permute(w, (0, 2, 1, 3, 4))\n",
    "w = w[:, :, (2, 0, 1), :, :]  # This permutation is needed because CEConv starts with RGB, whereas Conv3d starts with BRG.\n",
    "model_3d[0].weight = nn.parameter.Parameter(w)\n",
    "model_3d[0].bias = model_vanilla[0].bias\n",
    "\n",
    "y_3d = model_3d(x_3d)\n",
    "print(\"Output tensor \\t\", y_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the outputs are the same.\n",
    "torch.allclose(y_vanilla, y_3d, atol=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: \t torch.Size([16, 16, 3, 3, 3])\n",
      "Output tensor: \t torch.Size([1, 16, 3, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "# Define \"vanilla\" color equivariant model with single hidden layer.\n",
    "model_vanilla = nn.Sequential(\n",
    "    CEConv2D(\n",
    "        in_rotations=3,\n",
    "        out_rotations=3,\n",
    "        in_channels=16,\n",
    "        out_channels=16,\n",
    "        kernel_size=3,\n",
    "        padding=0,\n",
    "        separable=False,\n",
    "    ),\n",
    ")\n",
    "print(\"Weight: \\t\", model_vanilla[0].weight.shape)\n",
    "\n",
    "# Forward pass.\n",
    "y_vanilla = model_vanilla(x_hidden)\n",
    "print(\"Output tensor: \\t\", y_vanilla.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: \t torch.Size([16, 16, 3, 3, 3])\n",
      "Output tensor \t torch.Size([1, 16, 3, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "# Define Conv3d implementation of color equivariant model.\n",
    "model_3d = nn.Sequential(\n",
    "    nn.Conv3d(\n",
    "        in_channels=16,\n",
    "        out_channels=16,\n",
    "        kernel_size=(3, 3, 3),\n",
    "        padding=(1, 0, 0),\n",
    "        padding_mode='circular',\n",
    "    ),\n",
    ")\n",
    "print(\"Weight: \\t\", model_3d[0].weight.shape)\n",
    "\n",
    "# Copy weights from vanilla model to 3D model.\n",
    "w = model_vanilla[0].weight.data\n",
    "w = w[:, :, (2, 0, 1), :, :]\n",
    "model_3d[0].weight = nn.parameter.Parameter(w)\n",
    "model_3d[0].bias = model_vanilla[0].bias\n",
    "\n",
    "y_3d = model_3d(x_hidden)\n",
    "print(\"Output tensor \\t\", y_3d.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the outputs are the same.\n",
    "torch.allclose(y_vanilla, y_3d, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight layer 1: \t torch.Size([16, 3, 1, 3, 3])\n",
      "Weight layer 2: \t torch.Size([16, 16, 3, 3, 3])\n",
      "Weight layer 3: \t torch.Size([16, 16, 3, 3, 3])\n",
      "Output tensor: \t\t torch.Size([1, 16, 3, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "# Define \"vanilla\" color equivariant model.\n",
    "model_vanilla = nn.Sequential(\n",
    "    CEConv2D(\n",
    "        in_rotations=1, \n",
    "        out_rotations=3,\n",
    "        in_channels=3,\n",
    "        out_channels=16,\n",
    "        kernel_size=3,\n",
    "        padding=0,\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    CEConv2D(\n",
    "        in_rotations=3,\n",
    "        out_rotations=3,\n",
    "        in_channels=16,\n",
    "        out_channels=16,\n",
    "        kernel_size=3,\n",
    "        padding=0,\n",
    "        separable=False,\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    CEConv2D(\n",
    "        in_rotations=3,\n",
    "        out_rotations=3,\n",
    "        in_channels=16,\n",
    "        out_channels=16,\n",
    "        kernel_size=3,\n",
    "        padding=0,\n",
    "        separable=False,\n",
    "    ),\n",
    ")\n",
    "print(\"Weight layer 1: \\t\", model_vanilla[0].weight.shape)\n",
    "print(\"Weight layer 2: \\t\", model_vanilla[2].weight.shape)\n",
    "print(\"Weight layer 3: \\t\", model_vanilla[4].weight.shape)\n",
    "\n",
    "# Forward pass.\n",
    "y_vanilla = model_vanilla(x)\n",
    "print(\"Output tensor: \\t\\t\", y_vanilla.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tensor \t torch.Size([1, 16, 3, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "# Define Conv3d implementation of color equivariant model.\n",
    "model_3d = nn.Sequential(\n",
    "    nn.Conv3d(\n",
    "        in_channels=1,\n",
    "        out_channels=16,\n",
    "        kernel_size=(3, 3, 3),\n",
    "        padding=(1, 0, 0),\n",
    "        padding_mode='circular',\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv3d(\n",
    "        in_channels=16,\n",
    "        out_channels=16,\n",
    "        kernel_size=(3, 3, 3),\n",
    "        padding=(1, 0, 0),\n",
    "        padding_mode='circular',\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv3d(\n",
    "        in_channels=16,\n",
    "        out_channels=16,\n",
    "        kernel_size=(3, 3, 3),\n",
    "        padding=(1, 0, 0),\n",
    "        padding_mode='circular',\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Copy weights from vanilla model to 3D model.\n",
    "w = model_vanilla[0].weight.data\n",
    "w = torch.permute(w, (0, 2, 1, 3, 4))\n",
    "w = w[:, :, (2, 0, 1), :, :]\n",
    "model_3d[0].weight = nn.parameter.Parameter(w.clone())\n",
    "model_3d[0].bias = model_vanilla[0].bias\n",
    "\n",
    "w = model_vanilla[2].weight.data\n",
    "w = w[:, :, (2, 0, 1), :, :]\n",
    "model_3d[2].weight = nn.parameter.Parameter(w.clone())\n",
    "model_3d[2].bias = model_vanilla[2].bias\n",
    "\n",
    "w = model_vanilla[4].weight.data\n",
    "w = w[:, :, (2, 0, 1), :, :]\n",
    "model_3d[4].weight = nn.parameter.Parameter(w)\n",
    "model_3d[4].bias = model_vanilla[4].bias\n",
    "\n",
    "y_3d = model_3d(x_3d)\n",
    "print(\"Output tensor \\t\", y_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the outputs are the same.\n",
    "torch.allclose(y_vanilla, y_3d, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "\n",
    "* `torch.allclose` only returns `True` if the two tensors are equal within a relatively high tolerance, so there are some subtle numerical differences between the two implementations.\n",
    "* It would be interesting to see if the differences in the two implementations lead to different benchmark results.\n",
    "* The Conv3d implementation may be faster than the CEConv implementation, so may be worth replacing it under the hood.\n",
    "* I still have to implement the separable version of CEConv as Conv3d, but that should be straightforward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
